{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/adrian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    # Convertir el texto a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Eliminar puntuación\n",
    "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenizar el texto en palabras\n",
    "    palabras = word_tokenize(texto)\n",
    "    \n",
    "    # Eliminar palabras vacías (stop words)\n",
    "    palabras_limpias = [palabra for palabra in palabras if palabra not in stopwords.words('spanish')]\n",
    "    \n",
    "    # Unir las palabras limpias en una sola cadena de texto\n",
    "    texto_limpio = ' '.join(palabras_limpias)\n",
    "    \n",
    "    return texto_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Parse the XML file\n",
    "tree = ET.parse('dataset/train/TREC-2017-LiveQA-Medical-Train-1.xml')\n",
    "root = tree.getroot()\n",
    "# Crear una lista para almacenar las filas del CSV\n",
    "data = []\n",
    "\n",
    "# Iterar a través de la estructura XML y extraer la información\n",
    "for question in root.findall('NLM-QUESTION'):\n",
    "    questionid = question.get('questionid')\n",
    "    fRef = question.get('fRef')\n",
    "    subject = question.find('SUBJECT').text if question.find('SUBJECT') is not None else ''\n",
    "    message = question.find('MESSAGE').text\n",
    "    message_clean = limpiar_texto(message)\n",
    "    \n",
    "    for subquestion in question.find('SUB-QUESTIONS').findall('SUB-QUESTION'):\n",
    "        subquestionid = subquestion.get('subqid')\n",
    "        subquestion_focus = subquestion.find('ANNOTATIONS').find('FOCUS').text\n",
    "        subquestion_type = subquestion.find('ANNOTATIONS').find('TYPE').text\n",
    "        \n",
    "        for answer in subquestion.find('ANSWERS').findall('ANSWER'):\n",
    "            answerid = answer.get('answerid')\n",
    "            answer_text = answer.text\n",
    "            \n",
    "            # Añadir la fila a la lista de datos\n",
    "            data.append([ message_clean, subquestion_focus, subquestion_type, answer_text])\n",
    "\n",
    "# Convertir la lista a un DataFrame de Pandas\n",
    "df = pd.DataFrame(data, columns=['message', 'subquestion_focus', 'subquestion_type', 'answer'])\n",
    "\n",
    "# Guardar el DataFrame a un archivo CSV\n",
    "df.to_csv('dataset/train/train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = ET.parse('dataset/train/TREC-2017-LiveQA-Medical-Train-2.xml')\n",
    "root2 = tree2.getroot()\n",
    "\n",
    "# Crear una lista para almacenar las filas del CSV\n",
    "data2 = []\n",
    "\n",
    "for question in root2.findall('NLM-QUESTION'):\n",
    "    qid = question.get('qid')\n",
    "    subject = question.find('SUBJECT').text if question.find('SUBJECT') is not None else ''\n",
    "    message = question.find('MESSAGE').text\n",
    "    message_clean = limpiar_texto(message)\n",
    "    \n",
    "    for subquestion in question.find('SUB-QUESTIONS').findall('SUB-QUESTION'):\n",
    "        subquestion_focus = subquestion.find('ANNOTATIONS').find('FOCUS').text\n",
    "        subquestion_type = subquestion.find('ANNOTATIONS').find('TYPE').text\n",
    "        \n",
    "        for answer in subquestion.find('ANSWERS').findall('ANSWER'):\n",
    "            answer_text = answer.text\n",
    "            \n",
    "            # Añadir la fila a la lista de datos\n",
    "            data2.append([message_clean, subquestion_focus, subquestion_type, answer_text])\n",
    "\n",
    "# Convertir la lista a un DataFrame de Pandas\n",
    "df = pd.DataFrame(data2, columns=['message', 'subquestion_focus', 'subquestion_type', 'answer'])\n",
    "\n",
    "# Guardar el DataFrame a un archivo CSV\n",
    "df.to_csv('dataset/train/train2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeTest = ET.parse('dataset/train/TREC-2017-LiveQA-Medical-Train-2.xml')\n",
    "rootTest = treeTest.getroot()\n",
    "\n",
    "# Crear una lista para almacenar las filas del CSV\n",
    "dataTest = []\n",
    "\n",
    "# Iterar a través de la estructura XML y extraer la información\n",
    "for question in rootTest.findall('NLM-QUESTION'):\n",
    "    message = question.find('MESSAGE').text if question.find('MESSAGE') is not None else ''\n",
    "    \n",
    "    for subquestion in question.find('SUB-QUESTIONS').findall('SUB-QUESTION'):\n",
    "        subquestion_focus = subquestion.find('ANNOTATIONS').find('FOCUS').text if subquestion.find('ANNOTATIONS') is not None and subquestion.find('ANNOTATIONS').find('FOCUS') is not None else ''\n",
    "        subquestion_type = subquestion.find('ANNOTATIONS').find('TYPE').text if subquestion.find('ANNOTATIONS') is not None and subquestion.find('ANNOTATIONS').find('TYPE') is not None else ''\n",
    "        \n",
    "        for answer in subquestion.find('ANSWERS').findall('ANSWER'):\n",
    "            answer_text = answer.text\n",
    "            \n",
    "            # Añadir la fila a la lista de datos\n",
    "            data.append([message, subquestion_focus, subquestion_type, answer_text])\n",
    "\n",
    "# Convertir la lista a un DataFrame de Pandas\n",
    "df = pd.DataFrame(data, columns=['message', 'subquestion_focus', 'subquestion_type', 'answer'])\n",
    "\n",
    "# Guardar el DataFrame a un archivo CSV\n",
    "df.to_csv('dataset/test/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv(\"dataset/train/train1.csv\")\n",
    "train2 = pd.read_csv(\"dataset/train/train2.csv\")\n",
    "\n",
    "# Unir los DataFrames\n",
    "train = pd.concat([train1, train2], ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado a un nuevo archivo CSV\n",
    "train.to_csv(\"dataset/train/train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
